{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------\n",
    "## Step 0) Load Libraries\n",
    "##-------------------------------------\n",
    "## Array Manipulation\n",
    "import numpy as np                       \n",
    "## Data Frame Manipulation\n",
    "import pandas as pd                      \n",
    "## Change Directory in Python\n",
    "import os                                \n",
    "## To Split into test and train\n",
    "from sklearn.model_selection import train_test_split \n",
    "## SVM\n",
    "from sklearn.svm import SVC \n",
    "## CART\n",
    "from sklearn import tree\n",
    "## Use Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix \n",
    "## Visualize Tree\n",
    "import graphviz \n",
    "## Save Image\n",
    "from matplotlib.pyplot import *        ## Plot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------\n",
    "## Step 2) Functions\n",
    "##-------------------------------------\n",
    "## Function to evaluate predictions\n",
    "def imp_metrics(TP,TN,FP,FN):\n",
    "    \"\"\"\n",
    "   Function Name: imp_metrics\n",
    "   Input: TP,FN,TP,FP\n",
    "   Output: Accuracy, Recal, Precision, F1\n",
    "   Purpose: Find metrics to understand recovery of SVM\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Calculate Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "    \n",
    "    ## Calculate Recall\n",
    "    if(TP != 0 and FN != 0):\n",
    "        recall = TP/(TP+FN)\n",
    "    else:\n",
    "        recall = np.nan\n",
    "\n",
    "    ## Calculate Precision\n",
    "    if(TP != 0 and FP != 0):\n",
    "        precision = TP/(TP+FP)\n",
    "    else:\n",
    "        precision =np.nan\n",
    "\n",
    "    ## Calculate F1\n",
    "    if(precision == np.nan and recall == np.nan):\n",
    "        F1 = np.nan\n",
    "    else:\n",
    "        F1 = 2*((precision*recall)/(precision+recall))\n",
    "        \n",
    "    ## Concatenate    \n",
    "    metrics = np.array([accuracy,recall,precision,F1])\n",
    "    return(metrics.round(2))\n",
    "\n",
    "\n",
    "\n",
    "## Format Metrics\n",
    "def provide_results(cf_matrix,algo):\n",
    "    \"\"\"Uses confusion matrix to find 4 important metrics\"\"\"\n",
    "    ## Find True Positive & Negative and False Positive & Negative\n",
    "    TP = cf_matrix[0,0]\n",
    "    TN = cf_matrix[1,1]\n",
    "    FP = cf_matrix[0,1]\n",
    "    FN = cf_matrix[1,0] \n",
    "    ## Calculate Accuracy, Recal, Precision, F1\n",
    "    metrics = imp_metrics(TP,TN,FP,FN)\n",
    "    print('\\n',\n",
    "          algo + ' Accuracy : ',  metrics[0],'\\n',\n",
    "          algo + ' Recall: ',     metrics[1],'\\n',\n",
    "          algo + ' Precision: ',  metrics[2],'\\n',\n",
    "          algo + ' F1: ',         metrics[3])\n",
    "    \n",
    "def split_into_groups(x,type_split):\n",
    "    \"\"\"Split cut data based on splits\"\"\"\n",
    "    \n",
    "    if(type_split == 'median'): ## Based on Median\n",
    "        median_value = np.median(x)\n",
    "        new_x = np.where(x > median_value , 1, 0) \n",
    "    elif(type_split == 'percentile'):  ## Based on percentile\n",
    "        percents = np.percentile(x,[25,75])\n",
    "        new_x = np.where(x < percents[0] , 1,\n",
    "                         np.where((x > percents[0]) & (x < percents[1]),2,3))\n",
    "    return(new_x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------\n",
    "## Step 1) Load Data\n",
    "##-------------------------------------\n",
    "default_path = 'C:/Users/james/OneDrive/Documents/Important_Files/Favorite_5_ML algorithms'\n",
    "os.chdir(default_path)\n",
    "king = pd.read_csv('king.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------\n",
    "## Step 3) Curate Data\n",
    "##-------------------------------------\n",
    "## 1) Make Yes/No features into 1/0 features\n",
    "king['low'] = king['low'].map(dict(Yes=1, No=0))\n",
    "king['firstep'] = king['firstep'].map(dict(Yes=1, No=0))\n",
    "king['smoker'] = king['smoker'].map(dict(Y=1, N=0))\n",
    "king['drinker'] = king['drinker'].map(dict(Y=1, N=0))\n",
    "\n",
    "## 2) Make Gender into 1:Female and 0:Male\n",
    "king['gender'] = king['gender'].map(dict(F=1, M=0))\n",
    "\n",
    "## 3) Make Race into dummy variables and drop race feature\n",
    "race_variables = pd.get_dummies(king['race'])\n",
    "king = pd.concat([king,race_variables],axis = 1)\n",
    "king = king.drop(columns=['race'])\n",
    "\n",
    "## 4) Make Educational Level into dummy \n",
    "##    variables as well and drop educlv\n",
    "educlv_variables = pd.get_dummies(king['educlv'])\n",
    "king = pd.concat([king,educlv_variables],axis = 1)\n",
    "king = king.drop(columns=['educlv'])\n",
    "\n",
    "## 5) Make birth weight into a three levels variable \n",
    "##    based on percentiles and drop bwt\n",
    "king['bwt_class'] = split_into_groups(king['bwt'],'percentile')\n",
    "king = king.drop(columns=['bwt','low'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------\n",
    "## Step 4) Split Data into Training and \n",
    "## Test data frames\n",
    "##-------------------------------------\n",
    "## Split DF into Features and Labels\n",
    "response_variable = 'bwt_class'\n",
    "y = king[response_variable]\n",
    "X = king.drop(columns=[response_variable])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=44, \n",
    "                                                    test_size = 0.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SVM Accuracy :  0.65 \n",
      " SVM Recall:  0.1 \n",
      " SVM Precision:  0.57 \n",
      " SVM F1:  0.17\n"
     ]
    }
   ],
   "source": [
    "##-------------------------------------\n",
    "## Step 5) Implement SVM and view metrics\n",
    "##-------------------------------------\n",
    "\n",
    "## SVM specifications\n",
    "clf_svm = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovr', degree=2, gamma='auto', kernel='rbf',\n",
    "        max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "        tol=0.001, verbose=False)\n",
    "## Run SVM algorithm\n",
    "clf_svm=  clf_svm.fit(X_train, y_train)\n",
    "## Predict y_est_svm\n",
    "y_est_svm = clf_svm.predict(X_test) \n",
    "## Determine Confusion matrix\n",
    "cf_matrix_svm = confusion_matrix(y_est_svm,y_test)\n",
    "## Display Metrics\n",
    "provide_results(cf_matrix_svm,'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------\n",
    "## Step 6) Visualize SVM\n",
    "##-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CART Accuracy :  0.75 \n",
      " CART Recall:  0.32 \n",
      " CART Precision:  0.87 \n",
      " CART F1:  0.47\n"
     ]
    }
   ],
   "source": [
    "##-------------------------------------\n",
    "## Step 7) Implement CART and view metrics\n",
    "##-------------------------------------\n",
    "## CART specifications\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "## Run CART algorithm\n",
    "clf_cart = clf.fit(X_train, y_train) \n",
    "## Predict y_est_cart\n",
    "y_est_cart = clf_cart.predict(X_test)\n",
    "## Determine Confusion matrix\n",
    "cf_matrix_cart = confusion_matrix(y_est_cart,y_test)\n",
    "## Display Metrics\n",
    "provide_results(cf_matrix_cart,'CART')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree_length2.pdf'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-------------------------------------\n",
    "## Step 8) Visualize CART\n",
    "##-------------------------------------\n",
    "dot_data = tree.export_graphviz(clf_cart, out_file=None, \n",
    "                          feature_names=X_train.columns,  \n",
    "                          class_names=['Light','Medium','Heavy'],  \n",
    "                          filled=True, rounded=True,  \n",
    "                          special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('tree_length2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting SVM\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_svm_margin.html\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html\n",
    "## Data\n",
    "http://courses.washington.edu/b517/Datasets/datasets.html\n",
    "\n",
    "## Make better choices with Decision Trees\n",
    "http://scikit-learn.org/stable/modules/tree.html#classification-criteria\n",
    "\n",
    "## Data Reduction\n",
    "http://scikit-learn.org/stable/modules/decomposition.html#ica\n",
    "\n",
    "## View Decision Trees better\n",
    "http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html#sphx-glr-auto-examples-tree-plot-iris-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
